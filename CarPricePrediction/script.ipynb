{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAR PRICE PREDICTION\n",
    "\n",
    "- USING RANDOM FOREST REGRESSOR \n",
    "\n",
    "- DO SOME PREPROCESSING FOR THIS DATASET TOO !!!\n",
    "\n",
    "- LET US ALSO UNDERSTAND HOW THIS ALGORITHM WORKS:\n",
    "\n",
    "    -  Random Forest is like asking a bunch of friends for advice:\n",
    "\n",
    "        - Asking Friends: Let's say you have a big decision to make, like choosing a movie. Instead of asking just one friend, you ask several friends for their movie suggestions.\n",
    "\n",
    "        - Different Opinions: Each friend gives you a recommendation based on their own preferences and knowledge. Some might like action movies, some prefer comedy, and others might suggest drama.\n",
    "\n",
    "        - Voting System: You collect all their suggestions and choose the movie that gets the most votes. This way, you're considering various opinions before making your decision.\n",
    "\n",
    "    - Now, let's translate this analogy to the Random Forest algorithm:\n",
    "\n",
    "        - Multiple Decision Makers: Instead of friends, Random Forest creates multiple Decision Trees. Each tree is like a friend, making its predictions based on a subset of the data and features.\n",
    "\n",
    "        - Different Perspectives: These trees might focus on different aspects or patterns in the data. Some trees might pay attention to one set of features, while others look at different ones.\n",
    "\n",
    "        - Voting for the Best Prediction: When you need a prediction (e.g., classifying an item or predicting a value), each tree gives its answer. Then, the Random Forest collects these answers and makes its final prediction based on majority voting.\n",
    "\n",
    "        - Better Accuracy: By combining the opinions of multiple trees (or friends), the Random Forest tends to make better predictions than just relying on one Decision Tree. It reduces the chance of overfitting (making decisions based too much on one perspective) and tends to be more accurate.\n",
    "\n",
    "In simple terms, Random Forest is a team of Decision Trees working together, offering different perspectives to reach a better, more reliable decision or prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING STANDARD LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 26)\n",
      "   car_ID  symboling                   CarName fueltype aspiration doornumber  \\\n",
      "0       1          3        alfa-romero giulia      gas        std        two   \n",
      "1       2          3       alfa-romero stelvio      gas        std        two   \n",
      "2       3          1  alfa-romero Quadrifoglio      gas        std        two   \n",
      "3       4          2               audi 100 ls      gas        std       four   \n",
      "4       5          2                audi 100ls      gas        std       four   \n",
      "\n",
      "       carbody drivewheel enginelocation  wheelbase  ...  enginesize  \\\n",
      "0  convertible        rwd          front       88.6  ...         130   \n",
      "1  convertible        rwd          front       88.6  ...         130   \n",
      "2    hatchback        rwd          front       94.5  ...         152   \n",
      "3        sedan        fwd          front       99.8  ...         109   \n",
      "4        sedan        4wd          front       99.4  ...         136   \n",
      "\n",
      "   fuelsystem  boreratio  stroke compressionratio horsepower  peakrpm citympg  \\\n",
      "0        mpfi       3.47    2.68              9.0        111     5000      21   \n",
      "1        mpfi       3.47    2.68              9.0        111     5000      21   \n",
      "2        mpfi       2.68    3.47              9.0        154     5000      19   \n",
      "3        mpfi       3.19    3.40             10.0        102     5500      24   \n",
      "4        mpfi       3.19    3.40              8.0        115     5500      18   \n",
      "\n",
      "   highwaympg    price  \n",
      "0          27  13495.0  \n",
      "1          27  16500.0  \n",
      "2          26  16500.0  \n",
      "3          30  13950.0  \n",
      "4          22  17450.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "car_ID              0\n",
      "symboling           0\n",
      "CarName             0\n",
      "fueltype            0\n",
      "aspiration          0\n",
      "doornumber          0\n",
      "carbody             0\n",
      "drivewheel          0\n",
      "enginelocation      0\n",
      "wheelbase           0\n",
      "carlength           0\n",
      "carwidth            0\n",
      "carheight           0\n",
      "curbweight          0\n",
      "enginetype          0\n",
      "cylindernumber      0\n",
      "enginesize          0\n",
      "fuelsystem          0\n",
      "boreratio           0\n",
      "stroke              0\n",
      "compressionratio    0\n",
      "horsepower          0\n",
      "peakrpm             0\n",
      "citympg             0\n",
      "highwaympg          0\n",
      "price               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# READING THE DATASET\n",
    "\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head(5))\n",
    "\n",
    "# CHECKING FOR NULL VALUES\n",
    "\n",
    "print(data.isna().sum())\n",
    "\n",
    "# SPLITTING THE DATASET INTO DEPENDENT AND INDEPENDENT FEATURES\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "# DROPPING CATEGORICAL FEATURES AS THE RANDOM FOREST REGRESSOR CAN'T WORK WITH CATEGORICAL FEATURES\n",
    "\n",
    "numericalCols=X.select_dtypes(exclude=['object']).columns\n",
    "X = X[numericalCols]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE !!!\n",
      "3459518.385309146\n",
      "R2 SCORE !!!\n",
      "0.9409393599187422\n"
     ]
    }
   ],
   "source": [
    "# TRAINING AND TESTING THE MODEL \n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# EVALUATING THE MODEL \n",
    "\n",
    "print('MSE !!!')\n",
    "print(mean_squared_error(Y_test, Y_pred))\n",
    "\n",
    "print('R2 SCORE !!!')\n",
    "print(r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
